{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3997b1a3-e286-470f-980a-ff4b9ac5ab24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in d:\\jupyter\\lib\\site-packages (0.10.14)\n",
      "Requirement already satisfied: opencv-python in d:\\jupyter\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: absl-py in d:\\jupyter\\lib\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in d:\\jupyter\\lib\\site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in d:\\jupyter\\lib\\site-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: jax in d:\\jupyter\\lib\\site-packages (from mediapipe) (0.4.31)\n",
      "Requirement already satisfied: jaxlib in d:\\jupyter\\lib\\site-packages (from mediapipe) (0.4.31)\n",
      "Requirement already satisfied: matplotlib in d:\\jupyter\\lib\\site-packages (from mediapipe) (3.8.0)\n",
      "Requirement already satisfied: numpy in d:\\jupyter\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in d:\\jupyter\\lib\\site-packages (from mediapipe) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in d:\\jupyter\\lib\\site-packages (from mediapipe) (4.25.4)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in d:\\jupyter\\lib\\site-packages (from mediapipe) (0.5.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in d:\\jupyter\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in d:\\jupyter\\lib\\site-packages (from jax->mediapipe) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum in d:\\jupyter\\lib\\site-packages (from jax->mediapipe) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.10 in d:\\jupyter\\lib\\site-packages (from jax->mediapipe) (1.11.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\jupyter\\lib\\site-packages (from matplotlib->mediapipe) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\jupyter\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\jupyter\\lib\\site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\jupyter\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\jupyter\\lib\\site-packages (from matplotlib->mediapipe) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\jupyter\\lib\\site-packages (from matplotlib->mediapipe) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\jupyter\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\jupyter\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in d:\\jupyter\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in d:\\jupyter\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b26b19e-2112-4251-ba59-8c33df994706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d88f788f-d282-491b-9053-43efb4182974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\jupyter\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[x: 0.573015332\n",
      "y: 0.729772449\n",
      "z: -2.89979744\n",
      "visibility: 0.991139352\n",
      ", x: 0.618570924\n",
      "y: 0.642504692\n",
      "z: -2.86809182\n",
      "visibility: 0.988408148\n",
      ", x: 0.643945456\n",
      "y: 0.639309168\n",
      "z: -2.86823511\n",
      "visibility: 0.987620115\n",
      ", x: 0.66555655\n",
      "y: 0.637381792\n",
      "z: -2.86893106\n",
      "visibility: 0.986232638\n",
      ", x: 0.539208114\n",
      "y: 0.646566927\n",
      "z: -2.86403942\n",
      "visibility: 0.98851192\n",
      ", x: 0.517023802\n",
      "y: 0.645024419\n",
      "z: -2.86469698\n",
      "visibility: 0.987587094\n",
      ", x: 0.500830948\n",
      "y: 0.644265175\n",
      "z: -2.86513638\n",
      "visibility: 0.988213897\n",
      ", x: 0.709559083\n",
      "y: 0.644641161\n",
      "z: -2.27387214\n",
      "visibility: 0.988811851\n",
      ", x: 0.492460191\n",
      "y: 0.648172617\n",
      "z: -2.24742484\n",
      "visibility: 0.991166294\n",
      ", x: 0.623784542\n",
      "y: 0.807782769\n",
      "z: -2.6370647\n",
      "visibility: 0.988027811\n",
      ", x: 0.542687178\n",
      "y: 0.808560967\n",
      "z: -2.63261986\n",
     
      "visibility: 0.988340199\n",
      ", x: 0.488040596\n",
      "y: 0.639416099\n",
      "z: -1.98286855\n",
      "visibility: 0.989917338\n",
      ", x: 0.629857898\n",
      "y: 0.785213292\n",
      "z: -2.36764336\n",
      "visibility: 0.987780154\n",
      ", x: 0.541736\n",
      "y: 0.795578957\n",
      "z: -2.35412359\n",
      "visibility: 0.988440096\n",
      ", x: 0.885153472\n",
      "y: 0.898402\n",
      "z: -1.41106665\n",
      "visibility: 0.956262827\n",
      ", x: 0.340335727\n",
      "y: 0.941099763\n",
      "z: -1.25995386\n",
      "visibility: 0.960338354\n",
      ", x: 0.965093493\n",
      "y: 1.27684271\n",
      "z: -1.10203183\n",
      "visibility: 0.13684994\n",
      ", x: 0.233202815\n",
      "y: 1.31067586\n",
      "z: -0.957852662\n",
      "visibility: 0.144551784\n",
      ", x: 0.912106156\n",
      "y: 1.59607697\n",
      "z: -1.18839622\n",
      "visibility: 0.0224943329\n",
      ", x: 0.304915696\n",
      "y: 1.48448443\n",
      "z: -1.34941697\n",
      "visibility: 0.0231424514\n",
      ", x: 0.911873043\n",
      "y: 1.70538783\n",
      "z: -1.24466217\n",
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Make detections\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m results \u001b[38;5;241m=\u001b[39m pose\u001b[38;5;241m.\u001b[39mprocess(image)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# recolor back to BGR\u001b[39;00m\n\u001b[0;32m     19\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\jupyter\\Lib\\site-packages\\mediapipe\\python\\solutions\\pose.py:185\u001b[0m, in \u001b[0;36mPose.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mprocess(input_data\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m: image})\n\u001b[0;32m    186\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[1;32mD:\\jupyter\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:340\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    336\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    337\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    338\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mwait_until_idle()\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1. MAKE DETECTIONS\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "## SETUP MEDIAPIPE instance\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence = 0.5, min_tracking_confidence = 0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "            ## recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)    \n",
    "        image.flags.writeable = False\n",
    "        \n",
    "            # Make detections\n",
    "        results = pose.process(image)\n",
    "\n",
    "            # recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # extract landmark\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            print(landmarks)\n",
    "        except:\n",
    "            pass\n",
    "                \n",
    "            #render image\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color = (245,117,66), thickness=2, circle_radius=2),\n",
    "                                mp_drawing.DrawingSpec(color = (245,66,230), thickness=2, circle_radius=2)\n",
    "                                )\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break   \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ba41f01-6922-40d7-a02d-7561c50770f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f06f6d7-8b6e-402e-ab53-85e6196231c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "for lndmrk in mp_pose.PoseLandmark:\n",
    "    print(lndmrk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8336114-f5e8-407b-a124-e396802be415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.384405673\n",
       "y: 1.24632335\n",
       "z: -1.08135688\n",
       "visibility: 0.00767986104"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "966aac3a-3082-4f1b-adea-cb9052df5760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9675140976905823"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66c9d113-4aa6-42f6-adc1-fd54445c4568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.341651857\n",
       "y: 0.953940392\n",
       "z: -1.7133162\n",
       "visibility: 0.941085339"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18719406-3a71-4e16-96a9-c3dd2a05f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3 ACUTE ANGLES\n",
    "\n",
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # first\n",
    "    b = np.array(b) # mid\n",
    "    c = np.array(c) # end\n",
    "\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360.0 - angle\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca396ed9-062a-46c4-b1e0-fcee56a50e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y] \n",
    "elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y] \n",
    "wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "498b8805-3a09-4d58-b825-b959e8e4573b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.8816772699356079, 0.8828696012496948],\n",
       " [0.9545331001281738, 1.244297742843628],\n",
       " [0.9286531209945679, 1.4949520826339722])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoulder, elbow, wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79668ac7-d78b-4292-8fca-aed6cc42fdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162.70829632674972"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_angle(shoulder, elbow, wrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e095b88-2f55-4c73-a623-00a6132a15c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 597)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(np.multiply(elbow,[640,480]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d00442-4ca5-4bd9-a578-95fdd3e52a31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Curl counter variables\n",
    "counter = 0 \n",
    "stage = None\n",
    "\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            # Calculate angle\n",
    "            angle = calculate_angle(shoulder, elbow, wrist)\n",
    "            \n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(angle), \n",
    "                           tuple(np.multiply(elbow, [640, 480]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "            \n",
    "            # Curl counter logic\n",
    "            if angle > 160:\n",
    "                stage = \"down\"\n",
    "            if angle < 30 and stage =='down':\n",
    "                stage=\"up\"\n",
    "                counter +=1\n",
    "                print(counter)\n",
    "                       \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Render curl counter\n",
    "        # Setup status box\n",
    "        cv2.rectangle(image, (0,0), (225,73), (245,117,16), -1)\n",
    "        \n",
    "        # Rep data\n",
    "        cv2.putText(image, 'REPS', (15,12), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(counter), \n",
    "                    (10,60), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Stage data\n",
    "        cv2.putText(image, 'STAGE', (65,12), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, stage, \n",
    "                    (60,60), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c385f67d-d3eb-4af4-8ff6-cd63111755bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
